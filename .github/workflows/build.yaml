# build and test. need to be able to build on manylinux1 image + pass tests.
# run after passing local unit tests using pytest wrapped with libcheck and
# after valgrind has produced satisfactory results.
#
# can also deploy if commit is tagged with version-like tag.
#
name: build

on: push

env:
  # where to mount the top-level directory of the repo in docker
  DOCKER_MNT: /_build
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  # build manylinux1 wheels
  build_manylinux:
    runs-on: ubuntu-18.04
    strategy:
      matrix:
        # docker images for manylinux building (i686 and x86_64)
        docker_image:
        - quay.io/pypa/manylinux1_x86_64
        - quay.io/pypa/manylinux1_i686
      # no need to specify max-parallel as we upload wheels with different
      # names to the same artifact; this can be done in parallel.
    steps:
    - uses: actions/checkout@v2
    - name: Pull manylinux docker image
      run: docker pull ${{ matrix.docker_image }}
    - name: Build manylinux wheels on docker image
      # platform the wheels are built for is taken from matrix.docker_image.
      # current dir is mounted in docker as $DOCKER_MNT. run script in bash
      # shell so there's no need to make the file executable in docker image.
      # builds wheels for python versions 3.6-3.8 inclusive.
      run: > 
        docker container run -e DOCKER_MNT=$DOCKER_MNT -e
        DOCKER_IMAGE=${{ matrix.docker_image }} -v `pwd`:$DOCKER_MNT
        ${{ matrix.docker_image }} bash $DOCKER_MNT/tools/build_manylinux.sh
    - name: Install and test manylinux wheels on docker image with pytest
      # use --rm option to clean up afterwards. install and test wheels
      run: >
        docker container run -e DOCKER_MNT=$DOCKER_MNT -e
        DOCKER_IMAGE=${{ matrix.docker_image }} -v `pwd`:$DOCKER_MNT
        ${{ matrix.docker_image }} bash $DOCKER_MNT/tools/test_manylinux.sh
    - name: Upload manylinux wheel artifacts
      uses: actions/upload-artifact@v2
      with:
        name: dist_artifact
        path: dist
        # if no files, error
        if-no-files-found: error
  # build windows wheels
  build_windows:
    runs-on: windows-latest
    strategy:
      matrix:
        # python versions to test with
        python-version: [3.6, 3.7, 3.8]
      # no need to specify max-parallel as we upload wheels with different
      # names to the same artifact; this can be done in parallel.
    steps:
    - uses: actions/checkout@v2
    - uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    # numpy get_include is used in setup.py so we need numpy
    - name: Install Python dependencies from requirements.txt
      run: pip3 install -r tools/requirements.txt
    - name: Build Windows wheel
      run: python setup.py bdist_wheel
    - name: Install and test Windows wheel with pytest
      run: |
        pip install $(find dist/*.whl)
        pytest -rsxXP --pyargs c_npy_demo.tests
        c_npy_demo.bench -s 20,10
      # use bash shell since i don't know PowerShell
      shell: bash
    - name: Upload Windows wheel artifact
      uses: actions/upload-artifact@v2
      with:
        name: dist_artifact
        path: dist
        if-no-files-found: error
  # simply create tar.gz in dist which is uploaded to dist_artifact
  build_sdist:
    runs-on: ubuntu-18.04
    steps:
    - uses: actions/checkout@v2
    - name: Install Python dependencies from requirements.txt
      run: pip3 install -r tools/requirements.txt
    - name: Create tar.gz sdist
      run: python3 setup.py sdist
    - name: Upload sdist artifact
      uses: actions/upload-artifact@v2
      with:
        name: dist_artifact
        path: dist
        if-no-files-found: error
  # deploy job, depends on build_manylinux, build_windows, build_sdist
  deploy:
    runs-on: ubuntu-18.04
    # can only deploy after building wheels and tar.gz
    needs: [build_manylinux, build_windows, build_sdist]
    # run only if version tag is present
    if: ${{ contains(github.ref, 'refs/tags/v') }}
    steps:
    - uses: actions/checkout@v2
    - name: Download .tar.gz, manylinux wheel, and windows wheel artifacts
      uses: actions/download-artifact@v2
      with:
        name: dist_artifact
        path: dist
    - name: >
        Create new env variables SRC_ARTIFACT_PATH, SRC_ARTIFACT_NAME
      # appends definition to the GITHUB_ENV environment file.
      # SRC_ARTIFACT_PATH is the path to the .tar.gz source, RELEASE_VERSION
      # gives the version specified by the git tag, SRC_ARTIFACT_NAME is the
      # name of the .tar.gz that we upload to the release
      run: |
        echo "SRC_ARTIFACT_PATH=$(find dist/*.tar.gz)" >> $GITHUB_ENV
        echo "RELEASE_VERSION=${GITHUB_REF##*/}" >> $GITHUB_ENV
        echo "SRC_ARTIFACT_NAME=$RELEASE_VERSION.tar.gz" >> $GITHUB_ENV
    - name: Create production release
      # need id so we can reference the upload URL later to upload SRC_ARTIFACT
      id: create_release
      uses: actions/create-release@v1
      # tag and release name are identical
      with:
        # don't use RELEASE_VERSION since instances of refs/tags/ are 
        # automatically stripped from tag_name and release_name
        tag_name: ${{ github.ref }}
        release_name: ${{ github.ref }}
        body: >
          ${{ format('Release {0} deployed by GitHub Actions build. This text
          is auto-generated by create-release action.', env.RELEASE_VERSION) }}
    - name: Upload .tar.gz to release URL
      uses: actions/upload-release-asset@v1
      with:
        # use upload URL from the release creation step's outputs
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        # path to the asset, given by SRC_ARTIFACT_PATH
        asset_path: ${{ env.SRC_ARTIFACT_PATH }}
        # upload name for the asset, given by SRC_ARTIFACT_NAME
        asset_name: ${{ env.SRC_ARTIFACT_NAME }}
        # appropriate content type
        asset_content_type: application/gzip
    - name: Deploy manylinux1 wheels and .tar.gz source to PyPI
      uses: pypa/gh-action-pypi-publish@v1.4.1
      with:
        user: __token__
        password: ${{ secrets.LOCAL_PYPI_TOKEN }}